 Basically, the gist of it is I want to create kind of like an article spinner with like where if I put like a list in braces, then program will pick one item out of that list. Right. So kind of like text templating with braces. The single brace is easy peasy. Where I'm running into issues is I can't nest. so let's say if i want to create like i don't know um five levels of nested braces right if i want uh and this is for prompt generation right if i want like a unique ish sort of prompt every time i spin um then i don know how to one dynamically keep track of the braces depending on however In other words I having trouble coming up with an algorithm i could do it for one set of braces right that but i don know if i if user wants to get crazy and put in like 20 nest nested braces right i don't know how to keep track of that if they want to put in 100 or a thousand or a hundred trillion right how do i keep track of that without explicitly or hard coding. I don't know how to do that at all. So what data structure should immediately pop into your head when you think about these things? Interview question. I have a brace mapping problem. What data structure immediately should pop into your head? That's an array. Not strings. Not trees, that's overkill. Okay, I wanna understand this problem better. So you mean there's an object instead of object? Okay, put some text in front.  some text in front of the brace, Kevin, and put some after it. Or just make up with some scenario, whatever. So let's say the brown fox jump over the cat or something, right? And then inside that brace, I put in, instead of fox, I put in fox, bear, dog, deer, car, airplane, whatever. So you have basically subject, verb, object, for example. And now you want to have a whole bunch of fox, beer cat and then maybe you want to have jumps crawls flies trees bird and house for example but then you may take this whole thing and you may put it inside another more complicated correct absolutely so you going to end up with something that looks like this So you have things that are necessary to decide other things down to some arbitrary level Yeah Yeah so people are saying like okay a tree right And a tree is not a bad way to go in the sense that, like, you start with something and then you say, like, well, I have this node can contain however many things, right? And this node can contain however many things. And then each of these may, in turn, contain things, or they may be leaf nodes, right? Oh, this is a graph. well yeah trees are graphs right so that's that's a given right but you know you could you could do this right that would be you could do a tree and go down to to uh to leaf nodes right that's that would work and that reflects this structure here um but the question you asked was how do you match braces right so if as soon as i say how do i match braces what data structure should immediately be popular with that. What is braces? Curly braces. The curly braces, yeah. Oh, how do you match curly braces stack?  Yes, stack, right? So what you do is as you parse along here, right? As soon as you see a curly brace, right? There are different ways you could do it, but like what I can do is I can just remember, so I'm gonna have my stack, I'm gonna have it go sideways. I'm gonna have my stack go sideways. So I'm gonna put a curly brace on, right? And then I see this curly brace, I'll put another curly brace on the stack. And then I come along and I see this end brace. So I look at my stack and I'm like, oh, well that cancels this one, right? And then I go along and I see this. And that's why I put another curly brace. And I see another one. I put another curly brace. And I see this one. I'm like, oh, that cancels this one. And I see this one. And that cancels this one. And then I see this one, which cancels this one. And I'm done. And my snack is empty. So it's good. Right? Okay. So that is like the classic, how do I match delimiter kind of thing. Right? All right. Open and close delimiters Right now is that really what you want to do or is there something else you want to do Because if all you doing is you checking are the curly braces matched then that's enough, right, Scott? Yes. Unless it's something I'm not seeing, but... Well, so if all you're checking is syntactically, is it correct? Then that's fine. Now, if you're trying to process this stuff and do things with it, then you may end up it's possible you end up wanting to have a tree of some kind. Because this is like the ASD, the abstract syntax tree kind of structure, right? Where it's like, I want to take these things and I want to combine these with a plus and I want to take these things and combine them with a times. You know, it's like, depending on what you want to do, right? No, it's just basically, right. It's just basically pick one out of every set of braces and then just concatenate that to the hardcoded string that user provides and that's it. We're not doing any other calculation or anything with the items in each brace. That's the brace.  so you want to okay so what you're trying okay i see okay so what you're trying to do is you're trying to generate a sentence yes random okay okay so let's see what we can do with that okay so now if you want to generate a sentence okay so what we can do is we can say okay i so let's just come into here so i come into here i see an open brace okay and i come into here and I see an open brace. And I come to here, I see an open brace. Then I see... Fox, bear, cat. So I think what you're going to have to do is you're going to want to have for each... Ugh. So... So... I think you're going to maybe want to have another stack where the stack is... a list of the words in the current level so then you get to here and you're like okay well now i see fox bear cat and then i see a curly brace which cancels out this one right at that moment i can now choose a random word from whatever list is here right so let's just say i choose bear right so so better okay then this gets canceled out because you know these are gone right now i see an open brace right and so then i'm going to start my new list right and then i see jump jump climb crawl whatever and i see a close brace which cancels out this one right so then and and just to be clear this word that i picked bear i guess should go into this one should go into this list the one below it anyway no because I'm gonna pick oh so if I pick Fox jump house and then it seems like I'm gonna have this whole thing pick one of these words because that's what curly  braces do is they pick a word, right? Or is there, there seems like there's more syntax here, right? So. There was one requirement I forgot, I'm sorry. So also with this chaos of madness, that there is going to be other hard-coded strings in between the braces. So let's say, I don't know, I can't think of anything. Something that's going to, it's not in the list, but it's going to be in the braces. So doing it is sort of, you know, you know, while you're in this brace, if you detect one, then doing, you know, if unless you if you unless you detect a second brace, now you make you may and probably will come up with another word before you come up with another opening brace or closing. Yeah So it seems like there might be syntactically you might need something like curly braces choose one of the options inside and then maybe you want to have like a square brace or something here which says whatever's in here concatenate it into a single unit right so that now this one unit right this one string is now a entry in the bigger one or something like that like it seems like there might be a syntax a uh you need a syntax to tell the difference between when when do i randomly select an element and when do i concatenate the elements of the one and treat it as a thing okay right does that make sense yeah i mean it might make sense but does my question make sense it seems like there are two actions one is choose a random thing and the other one is concatenate or something yes and use that as a single element in a bigger collection. Where you may act, rinse, lather, and repeat. OK. Does that make sense? I got it to the last part where you said they'd  maybe to like a bigger well let's just say i have subject verb object here so i'm going to make a sentence right yeah and then over here i have subject verb object using the exact same thing and i get another sentence right and then i put these two sentences inside curly braces so i would put this as a bracket right so each of these individual ones selects selects this goes up here this goes to here and this goes to here and then the square brackets say make this a single thing and then when I have these curly brackets here well these outer curly brackets contain this sentence A and this sentence B and they're going to choose one of them random okay because it's like you see what I'm saying it seems like there are two operations one is well one is select random things and the other is for the random things concatenate them to an object right and then if that happens to be inside a bigger thing then do whatever the bigger thing wants to do with it right Which may be select it or concatenate it right yeah so so i feel like there are two two operations which may be why it's confusing and so in my example here like i'm just saying curly brace a b c right will return either a or b or c right like it returns one of these square bracket a b c returns a b c or something yeah right yeah and so if i have you know square bracket curly bracket a b c curly bracket def curly bracket g right then if i have square bracket curly bracket p q and then I have curly bracket ST,  and I have square bracket and curly bracket. So what's this going to do? So this is going to return, like let's just say this is going to turn into D, F, G, and this is going to turn into Q, S. And then that whole thing is going to select one of these at random. And so this will turn into Q, S maybe. Okay. Now what about when we get to the part of the list of the list? would it still be the same? Well, if I nest this into another thing, then it would just repeat this process until it comes back to one answer. Okay. At least that's how I see what you're asking. So basically, this whole process will eventually generate a single random string or sentence, right? Yes. However you decide to do it. Yep. And you can nest it however deep you want right Okay so fine So I think you can do So so I think you can do this So here computer science theory for you, right? This language is what's called a context-free grammar. So this can be solved using a state machine plus a stack. right so so if I have a stack and I have the appropriate logic I should be able to parse this grammar and of course you have like a little bit of a weird thing but your logic is not deterministic but it shouldn't really matter right you're condensing it down so this this should work right and so you you can do this with a stack from left or right I think should be okay So you don't actually have to have a tree per se  if you don't want it. So yeah, I think that should work. We'll find out. We'll be working on it all night. Yeah, so I think the trick is going to be you want to store the matching delimiter and so if you store a square bracket you know, whatever, you need to make sure that you match the appropriate delimiter and then when you encounter delimiter, you want to store the information that you found and when you see the closing delimiter, you take action on this thing and put it in the enclosing one. Yes. Yep. And then when you see the enclosing, you see this thing then you take an action on whatever is in that enclosing one and you put it into here. Right? Right. And if you're the last one, that's just your answer. So I think that'll work. Well, actually, no, let me take that back. So your example in the bottom right-hand corner, I see where you're going there. But think of that as like the A, B, C, D, E, F, and G, and H, I think, in that first list and the second list. G, right? That's why this has to be a G. Right. So that D, F, G is part of the prompt, and that 2S is part of the same prompt. So you're not picking out of those two. You just concatenate those two because both of those, they're two different objects. So in that case, you just change this to square brackets. So now it will concatenate. So concatenate will be dfgqs because that's what the square bracket says. This is concatenate whatever is in here. But it could generate different ones. It could generate a, d, g, q, t. That would be another one. Yeah. Yeah. So, yeah. So I think you just, yeah. If you, if you, if your intention was to concatenate these two answers,  soviet, right? You just change that. Okay. But I think the key is that you need to have a clear operation of select random and concatenate, right? They need to be different operations, otherwise it's just like you don't know what to do, right? Right. And if you wanted to go to the tree route, how would that be implemented? You said like the tree was kind of like overkill. I just wanted to see how that would look. So you can convert this as you go, right? You can say, okay, I have an open whatever. So this is going to be my up here. I'm going to have this, right? And then when I encounter a sub node, it's going to be like here, right? And then this might be a square bracket, and I have all these things. I have a square bracket. And then I put all these things, whatever these are, and then I close my brace. And then when I come up to here, I'm going to parse all this stuff, right? And eventually I get to this closing thing right closing thing right So you can see how here it just like DFS So what the DFS DFS is you start with the root node and you start pushing things onto a stack. And then you traverse and you backlog, you come back and you come back and you come back and come back. So this down here is basically DFS. We're not keeping track of the whole tree. We're just walking the tree. And so every time we get rid of a node, we just come back up or whatever. And so what you would do is instead of in DFS where you just get rid of the stuff that you're done with you just sort of keep it around right that will rebuild the tree okay right so so you could take this string and then you could basically run dfs on it but instead of when you get down to here and you back up you don't delete this you just attach it to the parent right or whatever right right and then you build you build the tree as you go right and to answer your question um i haven't tried it uh on the new models yet last time i tried I made this problem, what is it, a year and a half ago-ish? Almost two years ago.  gpt 3.5 turbo um it did the first you know one dimension is fine two dimensions it was kind of shaky three dimensions are higher that's where it just kind of fell apart yes nested nested list yeah that's what i meant um yeah it's just and of course it it what it was trying to do like i was saying it was trying to keep track of the number of opening braces and the closing braces and trying to balance it that way. And that doesn't work if, or it doesn't scale well if someone wants to get crazy and do like 200 different lists. Now, why would somebody want to do 200-something lists? Who knows? You know, people have the use, because I just wanted to scale infinitely, maybe not infinitely, but as large as possible without there being issues Yeah And that sort of the exact argument why you have to have a stack right So normally you have this thing called a regular expression where you just need this thing called a DFA. It's just a state machine, right? And the problem is that you can't match parentheses in a regular language because like you said, for every time I encounter a nested thing, I have to have a state for that, right? I have to have state and I have another state, but I have another state. And for a given number of parentheses, I will eventually run it for whatever you give me here. I can always generate a string that exhausts whatever state you have. So you have to have this plus a stack that can grow indefinitely to keep track of these things. And then the interesting thing is that if you... So this is sort of like a fun little diversion here. But if you have, so you have a regular language where you just need a DFA, a state machine, right?  DFA is a fancy way of saying a state machine. Okay. Okay. Then you have what's called context-free grammars, where you need a DFA plus a stack. Okay. Then you have Turing complete languages, right? Where all you need for this is a DFA plus two stacks, which is crazy, right? That like to go from a relatively restricted group of languages to anything that you can possibly compute, you just need to add one more stack. This is very weird. Anyway, some weird computer science theory for you. So next question. This is probably doing too much if we haven't gotten that point already. If I wanted to make this in Go how or any other language that has like parallel support concurrency support is that feasible or am I just putting myself in a world of pain if I even try to balance, you know, I wouldn't even know where to even start with that, but. So you're saying, like, if you have a really long string, you want to, like, I want to break it up. There are two ways that come to mind. At the top level, what you could do is you could find... You go through the highest level and you find the matching things, right? And then you could farm this off to thread one.  and you could farm this off to thread two, and you could farm this off to thread three, or async it, whatever. And then all these are going to return subtrees. And then you take these three things and you put them under this node. So you have T0 it finds a match and then it takes all the sub ones and farms them out so these can be done in parallel. and then you can repeat this process recursive right but the problem is you could like fork bomb yourself essentially right if you you know so what you really want to do is you really want to have like a thread cool or something that can you know you put these into you put all these tasks for q and then it will work them off yeah because i was just going to say if like for t1 when it let's say if it comes across like another uh i don't know five or six list does that right Right. Which it will, right? Presumably, you know, this will have something. And then the other thing is, like, this could have, like, hundreds of them, right? And that could just be it. And you don't want these things to be idle, right? You want these to eventually come over here and help out, right? Yep. So, yeah, so you want to have, like, you want to have a way to, like, process the current level, create a bunch of tasks, put those tasks into the thread pool, and then have the thread pool work them off. Okay. It'll produce new tasks as necessary, right? And then those go in and then you have to kind of make sure that, you know, threads are busy or whatever. This is exactly what I built with the interns a couple of summers ago. Right. It's like this is one of the tasks that we did was to build a task mechanism where I could easily take the kinds of work that we do and just pass it in. It was actually pretty clever. Like so. So the thing is, if I have a bunch of tasks, so here's a question. right so i have a task in that task so i'm gonna call this a right and it spawns off a1 and it spawns off a2 and it spawns off a3  Right. And then I have another task that gets put in, which is B and it spawns off B1 and B2. Right. What order should I process these tasks? so i have so right now i have this task has been started and this task has been started right and then it spawns off these tasks right and now this task is waiting on these results so what order do i process these i want to say a1 b1 a2 b2 and then a3 okay so okay so i start a1 right let's to say a1 okay and it's so I start a1 and it spawns off like let's say two more tasks so this will be a11 and a12 right okay so now it spawns off these tasks and then and then you saying I should also start be this one over here right so so i going to start this task yeah and then i going to uh spawn off like let just say this spawns off uh uh two tasks as well so b12 and b1 or b11 and b12 right yeah because the assumption is that there's a b then there's at least a b1 same or the yeah so on and so forth yeah or this task just finished right but this task didn't finish it spawned some other things right so so okay remember so let's just say i have let's just say i have um two threads right in my thread pool right so the first one this is work so t1 is here and t2 is here and then we spawn off these two things right but now these threads these threads are busy like or they're or they're you know like i can't spawn two more threads so what do i do you know because i've already used them and the task they're working on is not complete right  so somehow i have to have t1 figure out that it should come over here and start doing some stuff and i have to have t2 figure out we can come over here and start doing some things right and that's non-trivial it's interesting exercise right to figure out how to do that and then and then the other question is like okay suppose t1 finishes you know it it it it this task is doing whatever now it could so so this task is now frozen so it could go here or it could go here right why do i not why would i not come over here and start working this task because all the tasks in a1 may not be finished well there's a very clear reason why i should not do that i mean i could do that it would be okay to do so what i could do is i could have the task over here start this task and then eventually this task may launch another task right a21 right An A22 or whatever, right? And then I could you know start A3 right And I could have it launch and it would launch and pass right why is that a bad plan and this is all across one thread well two threads in this case but yeah well well i said one thread because b is busy with doing its own thing right so oh yeah i mean i mean i could have this thread come over here and start this one it doesn't really matter right it's just okay every thread just pick up a task and work right all right so But why would I not want to go sideways here? Why would I want to go down? A11 and A12? Why would I want to? A11 and A12? Well, sure, that's fine. But I mean, I could, it doesn't matter. i think i could work this one and have it do its thing you know that's i mean if i had something like this that would be a problem right because now i have a circular dependency right but yeah you can never have a second dependency in this sort of way right so so it's definitely a tree  but why would I much prefer to come down here than to come over here? So you're asking, why do you want to do breadth first instead of depth first? Am I correct in that? The other way. Why would I want to do depth first instead of breadth first? Yeah, that's what I meant. I don't know. I don't know. There's a very clear answer here. Wait, what's the question again? So why do I want when I working these tasks and each task is a subtask right and each task is a subtask right Now I have a choice Like whenever I make new tasks i can either for example start here and i could when this makes a subtask i could go down the tree right or i could just when this makes a subtask i could just put it in the queue and i could go sideways and go breadth first right so so the question is there's a reason why depth first is a better choice place than breakfast. And so the question is, what is the reason? Because that first is. Reach the end. And I mean, they'll all reach the end eventually. It's it's not. No, it works. Sorry, was the last part? fast it's all the same amount of time because it visits every task once right and the answer is not dependency because that's all I got  Yeah, they all will get the job done and the dependencies are all okay because it's a tree. But there's a very clear reason why I want to go deaf first. Easier to implement in the code? I mean, it's not that different. This is a generic question or a context specific question? It's context specific, but the answer is surprisingly simple engineer. Normally people don't say the depth for search is better than breadth for search. I mean, it depends on who you hang out with. I have no clue. Because I am going to try to break the algorithm the moment I have one. I'm going to try a 500 nested list and see if it holds better. It'll show up. So here's the thing, right? Count how many... Count how many... So I'll do the left one depth first. I'll do the right one breadth first. Right. OK, so so I'm going to open this one. This one generates some tasks. And I'm going to hear this one generates some tasks. So so so just to be clear, these other ones have not been wrong. Right. So then this generates some tasks. I come to here and then this generates some tasks. Right. And then eventually. These are going to roll up. Right. And so, so all of this, this all gets done. And then this comes to here and then I come down here. Right.  do this and this launches some tasks and then these all get done right and then this finishes right then i come here and now this one this one's waiting on this so i have to do this one right so i come here and i do this and then this launches a bunch of tasks and then i i go to the first one right i do the first one and then this all rolls up right and then i come to the second one and it all rolls up right and eventually okay so so at any given time how many tasks do i have opened up with work being done? If I'm doing depth first search? How many tasks open up? In general. Not in this exact example, but in general, if I have two or more Well I mean the depth of the tree exactly The height of the tree number of tasks equals the height of the tree okay okay now let do the same thing on the right hand side but we going to do breadth first search right okay so i come in here this generates these tasks i come to here this generates some tasks right and then i come to here because that's where i go breath first right then, this generates some tasks, right? So now I come to here. And it generates some tasks, right? And then I come. So, it's waiting on these. And then I come to here. And this generates some tasks. And I come to here. And this generates some tasks. And this comes to here, and generates some tasks. Then I come over here, and then I do this one. And it generates some tasks. And I come to here, and it generates tasks. And so how many nodes? How many tasks do I have open at any given time, actually? A lot more. Like all of them. Like number of tasks, so BFS.  you know, number of tasks equals number of nodes. So all the nodes in level three, all the nodes in level four have to be complete before anything gets rolled up to level three on the BFS? Yeah. Okay. It's really bad, right? Now, normally when people talk about BFS, you process this node and then you're done with it and then you go to these nodes, you're done with those, but that's not the case here right like i need to roll up the answers and get them back up to the original task right so i can't get rid of that task until i'm done done right right and so there's a huge duplication in terms of like memory usage or whatever right where it's like right i could easily run out of memory in the case where um i doing bfs right right now is it always pathologically bad no but it like it not good right and there a whole other set of things which is kind of interesting which is like you know suppose I have a task suppose I have like this task spawns off like 10,000 tasks right yeah and then I get like another little task comes in here let's I have like a my new task C right it comes in here it's just like one little task between T1 and T2 task C is never going to get done because it's like this thing just keeps spawning tasks and this one keeps spawning tasks and so the probability that this thing ever makes it to the top of the heap is like nothing so we had a whole other thing about every task is a task group kind of like what I'm showing here where if you put this into a different group then the threads will split their time across the different task groups so that no task ever gets starved. So if I had...  if i had in this case two threads then t1 would do a task from here and then t1 would come over here and do this one and then t1 would come back over here right or t2 would come over here but they would keep going back and forth between the groups but if i had like five threads then you know maybe t3 would be over here but t1 t t4 t5 t6 and t7 might all be over here so like every thread is always busy but no no task group ever gets starved right like right you know so if i have some mammoth task and i have 100 cores like all 100 cores gonna be working on that text but then if i drop in like a little rinky-dink task like one of those cores will immediately service that task and then go back to this one right so so it's actually a pretty it was pretty slick like the solution that we came up to to not only keep the memory under control but also make sure that all the processes were not starved and also to be able to keep track of everything and you know of course there like tons of currency going on here so we have to be careful with all that stuff But isn there a problem don you have to count like the tasks first before anything even gets started so you can come up with the optimal sort of workflow we don't know how many tasks there are because when you launch a task i have no idea how many tasks the tasks will launch right so i just do the task and then it launches tasks and then those go into the queue and then you process it you can't know in advance okay but every time a task creates a task then that subtask has the same group as the parent just like when you grab a process create a child process like it still has that parent process so it doesn't matter how busy a thread is or a task is as long as it's busy so for instance if as long as uh t3 is working um t1 is working that's fine as well even though it has significantly more child notes so just to be clear  thread this is thread one right so that's what i meant yeah yeah so so so if i have 10 threads in my thread pool right most of them are going to be on t1 and t2 right yeah t3 will not be will not be started like t3 will definitely get treatment pretty soon right and so it's interesting so what what do we what do we do so what happens is we had something like um uh well when it comes to scheduling things, what data structures are popping to your head? Because that's why I was just going to ask, how does it know T3 is over there waiting, go do something over there. How does it know? I don't know. I'm guessing that's probably programming language specific, maybe? It's pretty generic. Just think about it. Whenever I have a scheduler and I say, give me the next thing to schedule, what data structure does that screen? FIFO is not the best choice because FIFO will leave the starvation. Like T1, T2 already put hundreds of tasks into the FIFO. That means... So stacker Q is not the best choice. There's a better data structure for this. What data structure lets you prioritize things? Priority Q? priority queue right exactly right so so a heap right of some kind priority queue right so what happens is uh at least you know one way to do it right is you can say okay look i'm gonna have a priority queue which is basically a heap right actually i'll just draw it i'll just draw it this way right so uh it's a priority queue and so i'm gonna have task a and then task b and then task c Right? And then A is going to have all of its subtasks.  that are currently cooking, right? Or that we know about. And task B is going to have all of its subtasks, right? And remember, these can be really, really long, right? Because it might be a huge task. I mean, task C is just like some rinkering task, right? So what's going to happen is, let's just say that I have two threads. So I have T1 and T2, right? So I have T1 and T2. And so T1 is going to come in and say, okay, task A needs some work. So I'm going to take this thing and I'm going to start working. And T2, so that moves this down to the bottom. Task A just got some servicing and so now it goes to the back of the queue. And then now task B is at the top. So thread 2 is going to pull this off and now B goes to the bottom of the queue. And so C is now at the top. And so as soon as one of these finishes it going to handle C But then they both immediately go back to A and B Just a question You did say that we wouldn know ahead of time how many tasks needs to be complete So how do we know that A is going to be at the top Well, it's just A was the first task we get put in. So it's just going to go to the top, right? Because it's the only task at that point. It's going to launch more tasks, right? So the thing though is like, so there's two orderings here, right? There's an ordering in here, which is kind of like your depth first search right yeah and then there's an ordering here which is oh this way right which lets no task ever get started right so if i had let's just say i had you know t3 t4 t5 t6 and t7 right well t1 and t2 will pull these off and then t3 will take this And then T4 will immediately start pulling this one off and T5 will pull this one and T6 will pull this one. So all the threads are always busy  as there's a task to be done like they will always find a task to do yeah yeah but you know these so these two tasks will get most of the cpu because of the biggest tasks but you know if i drop in a new task like d right as soon as these things get some work done this one will rocket to the top and then get worked right so it doesn't have to wait for those giant bats to finish right okay so anyway Anyway, it's like an interesting game of like, it's like a priority queue of stacks or decks or something, right? Where it's like, you know, within each, you keep the groups cycling, and then you have within each group, what's the next thing to do, right? So anyway, this was like a fun little exercise for the interns. Okay. One intern out of several worked on this one. But it came out really cool. Like, it's pretty nice. so all right because the nice thing about it is that is that yeah I not sure I not saying you should do this but I just saying like these are the kinds of things you might think about right when you go into this currency whatever thing but the the thing that was interesting about this is so the nice thing about this right is that it separates when I create tasks right so if I'm writing code right the problem in the code is if I'm running a code and I If I have a... For x equals 1 to 100, do f of x. The problem is I don't want to have to... I want to be concurrent. So I want to go faster. So what I really want to do is I don't want to do f of x. What I really want to do is I want to schedule f of x. I want to say these can all be done in parallel. right but the problem is if I have I don't know if I  have 10 cores or 100 cores or I don't know like if all those cores are already being used or I don't know like what else is going on in my program right so it's like this is not a good plan because if I have to know how many threads there are and how to know I have to work and everything else like that's just not not a good plan right because then if I do that and then they change number of threads and it's like the whole thing calls part right so so this is nice because what what we can do is you can schedule all these things and And then no matter how many threads I have, it will do the right thing. And then it doesn't matter. I don't know if I'm like the boss or if I'm inside another thing. I could be like inside another thing. Is that another thing? I don't know how many of these have been forked off or whatever. So it's kind of nice to have the ability to just create tasks. We say these tasks can be done in parallel. And then let somebody else figure out how to do that. Because sometimes what things do is they always launch a thread I launch a threads Then suddenly the entire computer is bogged down because I launched hundreds of threads and I didn realize I was inside something else. I also launched 100 threads. It gets crazy. It's nice to be able to have the ability to launch a task and then have it go to a controlled thread pool where if my user says I'm only allowed to use five cores, so be it. I'll have five worker threads or four worker threads or whatever the right number is right and i'll never go past that right so yeah it's pretty nice or if i just have one thread like there's nothing here that says you know if you just make the number of workers or whatever equal to one or zero or whatever the magic number was right it'll just run as if it was you know normal code just written in a loop Right. Right. So. Would it make a difference, then this would be better implemented in C or C, C++ or something like Go?  I don't know about Go, but I know that Go does have pretty good concurrency support and channels and passing information. Yeah, it's kind of like there. I think it's kind of built like that. Yeah. So, I mean, then there's like, is it Eiffel? I forget. What's the one that there's like a whole, there's another language, which is like just 100% like agent based. If everything is basically, no, it's not Haskell. It's, I think it's either Eiffel or what's the other one? Not Elixir. But anyway, one of those languages, I think it's Eiffel. It's by default, everything is like its own agent, and it just communicates this way. Eiffel? What's the name of that? This is my first time hearing about that. I think it's Eiffel. How do you spell that? I think it's just like the Eiffel language. Like Eiffel Tower? Yeah, I think so. Eiffel programming language. I think this is, let me just check. I've messed with it like once like a million years ago yeah yeah yeah yeah yeah my problem is if I come up with a worker solution or if Claude comes up with one rather I'm going to be tempted to just stay on single thread because, you know, cardinal rule of programming. We'll try to make it faster and then, you know, back to square one, you go. Make it work, right? And then make it fast. Yeah. Which programming language has everything everything  concurrent with agents and message passing. Erlang, that might be it. I thought it'd be an E. Erlang. That's how I heard. Erlang and Elixir. sounds difficult yeah open telephone platform okay yeah so this is the one because because I know it was written for the phone system and so like they just it's just like if you run it on your computer and it works then you just like have you know this on this computer that on that computer it just automatically like does all the concurrency I haven't messed with it too much but it's like I can definitely see why they did it right does it automatically yeah yeah interesting yep so so yeah i haven i haven't um used this much i'm not like a any stretch of expert on it but it's like it's pretty it seems pretty nice right now maybe the syntax is all whacked but it's like um yeah everything is just agent-based and thread-based. It's like everything runs in its own thread or process or whatever. Everything communicates through message queues and whatever that can be distributed. I guess it was Erlang, not Eiffel. Okay. We'll see how it goes. I would imagine Go has some influence from Erlang. I would guess. Yeah. Go language. Yeah, it's kind of like their claim to fame. I just want to know if they explicitly  I guess at least not here. I was wondering if, let me just search for her line here. I guess they hold a little bit maybe. so this is another example where remember how when we talk about concurrency i talk about how if you have any actors right any actor acting on a resource like this is a you know and that uses the word actor right any actor doesn have to be a threat or process it could be whatever I don I don follow what do you mean say that again when we talk about currency right yeah um i talk usually i phrase it as when you have agents or actors or something like that yep i don't say threat or process or whatever it's just like it doesn't matter right it's like an agent or an actor and the actor models are kind of like these um you might have heard of like these automaton like these uh cellular automata kind of thing right where you have like these little these little cells and each cell like does whatever the cell does and it kind of when it bumps another cell it's like oh interact and you're over here interact and like these systems emerge right you know these little like you know they use them to simulate you know people trying to get off an airplane in a fire or like in evacuating a building or whatever they make a bunch of little a little little automata right they have like like i'm a old lady or i'm a you or I'm a huge honking weightlifter guy, right? And they all have their own individual little behaviors and whatever. And so when you say evacuate the building,  They all try to do stuff, and they all have different goals and different whatever. When they interact, they do whatever. They're really good at simulating these traffic patterns or whatever. Those are agent models where each little thing has this whole thing. These kinds of designs are based on agent models where you have each little agent or actor, thread, process, whatever it is, like sending little messages to things you know that interacted in very asynchronous you know ways right like nobody pauses while somebody else knows their thing they just send a message and then this thing does something and then later on you get a message back or or you don't or whatever right so so uh those are like agent models and they're very distributed that's like the nature of distributed systems right you end up in this agent or actor model unreliable communication. I get the only real difference might just be like, you know, a lot of these things, like they assume the communication is reliable, right? If I send a message, it gets there eventually or whatever, right? As opposed to complete network failure, right? Yeah. But, but, yeah, that's why when we talk about concurrency, I talk about two actors or two agents or whatever doing something concurrently as opposed to two threads or two processes or whatever, right? It doesn't matter. Right. Once you enter this world, you're in the world of concurrency and you have to worry about it. all that stuff. Right. So anyway, let's see. So Ken had a question, I think about floating point numbers or something. So just the difference between fixed point and floating point or something like that. So we can do that real quick, but. All right, Kevin, I'm off for that. I'll talk tomorrow. Yeah. See you tomorrow. Hopefully. All right. Let's see.